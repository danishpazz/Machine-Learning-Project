{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sys,os\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>391</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Mr. William Ernest</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>310</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Francatelli, Miss. Laura Mabel</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17485</td>\n",
       "      <td>56.9292</td>\n",
       "      <td>E36</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Mallet, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>S.C./PARIS 2079</td>\n",
       "      <td>37.0042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Nenkoff, Mr. Christo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349234</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>816</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fry, Mr. Richard</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112058</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B102</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Baumann, Mr. John D</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17318</td>\n",
       "      <td>25.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>650</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Stanley, Miss. Amy Zillah Elsie</td>\n",
       "      <td>female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CA. 2314</td>\n",
       "      <td>7.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vanden Steen, Mr. Leo Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345783</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Miss. Ellis Anna Maria</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>603</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Harrington, Mr. Charles H</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113796</td>\n",
       "      <td>42.4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Spencer, Mrs. William Augustus (Marie Eugenie)</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17569</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>B78</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Touma, Mrs. Darwis (Hanne Youssef Razi)</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2650</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>372</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wiklund, Mr. Jakob Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3101267</td>\n",
       "      <td>6.4958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hagland, Mr. Ingvald Olai Olsen</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65303</td>\n",
       "      <td>19.9667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>540</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Frolicher, Miss. Hedwig Margaritha</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13568</td>\n",
       "      <td>49.5000</td>\n",
       "      <td>B39</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "390          391         1       1   \n",
       "309          310         1       1   \n",
       "817          818         0       2   \n",
       "223          224         0       3   \n",
       "815          816         0       1   \n",
       "168          169         0       1   \n",
       "649          650         1       3   \n",
       "355          356         0       3   \n",
       "119          120         0       3   \n",
       "602          603         0       1   \n",
       "31            32         1       1   \n",
       "255          256         1       3   \n",
       "371          372         0       3   \n",
       "451          452         0       3   \n",
       "539          540         1       1   \n",
       "\n",
       "                                               Name     Sex   Age  SibSp  \\\n",
       "390                      Carter, Mr. William Ernest    male  36.0      1   \n",
       "309                  Francatelli, Miss. Laura Mabel  female  30.0      0   \n",
       "817                              Mallet, Mr. Albert    male  31.0      1   \n",
       "223                            Nenkoff, Mr. Christo    male   NaN      0   \n",
       "815                                Fry, Mr. Richard    male   NaN      0   \n",
       "168                             Baumann, Mr. John D    male   NaN      0   \n",
       "649                 Stanley, Miss. Amy Zillah Elsie  female  23.0      0   \n",
       "355                     Vanden Steen, Mr. Leo Peter    male  28.0      0   \n",
       "119               Andersson, Miss. Ellis Anna Maria  female   2.0      4   \n",
       "602                       Harrington, Mr. Charles H    male   NaN      0   \n",
       "31   Spencer, Mrs. William Augustus (Marie Eugenie)  female   NaN      1   \n",
       "255         Touma, Mrs. Darwis (Hanne Youssef Razi)  female  29.0      0   \n",
       "371                       Wiklund, Mr. Jakob Alfred    male  18.0      1   \n",
       "451                 Hagland, Mr. Ingvald Olai Olsen    male   NaN      1   \n",
       "539              Frolicher, Miss. Hedwig Margaritha  female  22.0      0   \n",
       "\n",
       "     Parch           Ticket      Fare    Cabin Embarked  \n",
       "390      2           113760  120.0000  B96 B98        S  \n",
       "309      0         PC 17485   56.9292      E36        C  \n",
       "817      1  S.C./PARIS 2079   37.0042      NaN        C  \n",
       "223      0           349234    7.8958      NaN        S  \n",
       "815      0           112058    0.0000     B102        S  \n",
       "168      0         PC 17318   25.9250      NaN        S  \n",
       "649      0         CA. 2314    7.5500      NaN        S  \n",
       "355      0           345783    9.5000      NaN        S  \n",
       "119      2           347082   31.2750      NaN        S  \n",
       "602      0           113796   42.4000      NaN        S  \n",
       "31       0         PC 17569  146.5208      B78        C  \n",
       "255      2             2650   15.2458      NaN        C  \n",
       "371      0          3101267    6.4958      NaN        S  \n",
       "451      0            65303   19.9667      NaN        S  \n",
       "539      2            13568   49.5000      B39        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in training data\n",
    "training_data = pd.read_csv(\"/Users/vishaladdala/Desktop/TITANIC/dataset/train.csv\")\n",
    "training_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data statistics using .describe()\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Transformations\n",
    "#method to convert ages to bins called 'Unknown'for [-1,0], 'Baby' for [0-5],\n",
    "#'Child' for [6-12], 'Teenager' for [13-19], 'Student' for [20-25], 'Young Adult' for [26-35], 'Adult' for [36-60],\n",
    "#'Senior' for [61-100]\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 19, 25, 35, 60, 100)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method which simplifies the cabin feature by filling N/A values with 'N'\n",
    "#also it takes only the first letter the cabin using splicing\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to convert fares into bins using the numbers from .descrobe() statistics earlier\n",
    "#the N/A values are filled with -0.5\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Extraction \n",
    "#the below method is used to extract two features from the Name column\n",
    "#method to format the Name column to extract LName and NamePrefix\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to drop the features which we inconsider inconsequential\n",
    "#we have selected ticket,Name,Embarked columns to be dropped due lack of variance or too many N/A values\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this method calls all the above transformation methods one by one and applies it on our dataframe\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we proceed to proceed to apply the transformations on the training data\n",
    "transformed_train = transform_features(training_data)\n",
    "transformed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as we can see above our training data now has :\n",
    "#1. LName, NamePrefix instead of 'Name' which has been dropped\n",
    "#2. 'Ticket', 'Name', 'Embarked' have been dropped \n",
    "#3. 'Fare', 'Age' have been converted into convenient bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1020</td>\n",
       "      <td>2</td>\n",
       "      <td>Bowenur, Mr. Solomon</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211535</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1188</td>\n",
       "      <td>2</td>\n",
       "      <td>Laroche, Miss. Louise</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>SC/Paris 2123</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1009</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Beatrice Irene</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1083</td>\n",
       "      <td>1</td>\n",
       "      <td>Salomon, Mr. Abraham L</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111163</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                             Name     Sex   Age  \\\n",
       "128         1020       2             Bowenur, Mr. Solomon    male  42.0   \n",
       "296         1188       2            Laroche, Miss. Louise  female   1.0   \n",
       "413         1305       3               Spector, Mr. Woolf    male   NaN   \n",
       "117         1009       3  Sandstrom, Miss. Beatrice Irene  female   1.0   \n",
       "191         1083       1           Salomon, Mr. Abraham L    male   NaN   \n",
       "\n",
       "     SibSp  Parch         Ticket     Fare Cabin Embarked  \n",
       "128      0      0         211535  13.0000   NaN        S  \n",
       "296      1      2  SC/Paris 2123  41.5792   NaN        C  \n",
       "413      0      0      A.5. 3236   8.0500   NaN        S  \n",
       "117      1      1        PP 9549  16.7000    G6        S  \n",
       "191      0      0         111163  26.0000   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we proceed to apply the above feature transformations on the test data\n",
    "test_data = pd.read_csv(\"/Users/vishaladdala/Desktop/TITANIC/dataset/test.csv\")\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Kelly,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Wilkes,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Myles,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Wirz,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Hirvonen,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex          Age  SibSp  Parch        Fare Cabin  \\\n",
       "0          892       3    male  Young Adult      0      0  1_quartile     N   \n",
       "1          893       3  female        Adult      1      0  1_quartile     N   \n",
       "2          894       2    male       Senior      0      0  2_quartile     N   \n",
       "3          895       3    male  Young Adult      0      0  2_quartile     N   \n",
       "4          896       3  female      Student      1      1  2_quartile     N   \n",
       "\n",
       "       Lname NamePrefix  \n",
       "0     Kelly,        Mr.  \n",
       "1    Wilkes,       Mrs.  \n",
       "2     Myles,        Mr.  \n",
       "3      Wirz,        Mr.  \n",
       "4  Hirvonen,       Mrs.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_test = transform_features(test_data)\n",
    "transformed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now as a next step, we need to remember that machine learning algorithms need all the input to be numerical values\n",
    "#But as we can observe from above 'Sex', 'Age' , 'Fare', 'Cabin', 'Lname', 'NamePrefix' are in nominal(string) format\n",
    "#Hence we need to convert these into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7    100   \n",
       "1            2         1       1    0    0      1      0     3      2    182   \n",
       "2            3         1       3    0    7      0      0     0      7    329   \n",
       "3            4         1       1    0    7      1      0     3      2    267   \n",
       "4            5         0       3    1    7      0      0     1      7     15   \n",
       "\n",
       "   NamePrefix  \n",
       "0          19  \n",
       "1          20  \n",
       "2          16  \n",
       "3          20  \n",
       "4          19  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we proceed to use LabelEncoder from sklearn preprocessing to achieve \n",
    "#Every column in numerical form\n",
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "    \n",
    "data_train, data_test = encode_features(transformed_train, transformed_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>401</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>843</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>552</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>851</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>342</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  NamePrefix\n",
       "0          892       3    1    7      0      0     0      7    401          19\n",
       "1          893       3    0    0      1      0     0      7    843          20\n",
       "2          894       2    1    3      0      0     1      7    552          19\n",
       "3          895       3    1    7      0      0     1      7    851          19\n",
       "4          896       3    0    4      1      1     1      7    342          20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we proceed to test the various classifiers in Scikit-Learn to \n",
    "#see which classifiers works best on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "#Below we are splitting up our training data into 80% training , 20% testing data \n",
    "# X contains all the columns except 'Survived' because that is the feature we predict\n",
    "# Y consists only of the column 'Survived'\n",
    "X = data_train.drop(['Survived'], axis=1)\n",
    "Y = data_train.Survived\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 13]\n",
      " [26 42]]\n",
      "0.782122905028\n"
     ]
    }
   ],
   "source": [
    "#Our first classifier will be Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.518131567181  -  0.519763581489\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "classifiers = {}\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.525357142857  -  0.555075452716\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.618025933378  -  0.618025933378\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SVM\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.533551307847  -  0.533551307847\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.681056338028  -  0.681056338028\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LR\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.563109769729  -  0.563109769729\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.832671026157  -  0.828344511514\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RF\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.800313547954  -  0.800313547954\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 1)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"ADA\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.794973731277  -  0.800587413369\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 30,learning_rate = 1)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GB\"]=clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.532415045831  -  0.532415045831\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "#clf.set_params(max_iter = 1000,alpha = 0.01)\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"PT\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "NN\n",
      " :  0.564758551308    0.546126201654\n",
      "DNN\n",
      " :  0.538035434831    0.560314106863\n",
      "SVM\n",
      " :  0.618025933378    0.618025933378\n",
      "NB\n",
      " :  0.533551307847    0.533551307847\n",
      "LR\n",
      " :  0.681056338028    0.681056338028\n",
      "KNN\n",
      " :  0.563109769729    0.563109769729\n",
      "RF\n",
      " :  0.828305387883    0.822710149788\n",
      "ADA\n",
      " :  0.800313547954    0.800313547954\n",
      "GB\n",
      " :  0.796402302705    0.794973731277\n",
      "PT\n",
      " :  0.532415045831    0.532415045831\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hence we see that Random forest classifier gave the best performance with an accuracy ~83% and an F-score ~83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next we proceed to apply \"Feature Scaling\" to see if the performance of our various classifiers improves\n",
    "#Feature scaling aims to bring the values of our numerical features between 0 and 1\n",
    "#This is mainly done because large numerical values may skew our data and make the classifier weight it more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = data_train.drop(['Survived'], axis=1)\n",
    "YY = data_train.Survived\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "XX[XX.columns] = scaler.fit_transform(XX[XX.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.209919</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.379469</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp  Parch  Fare  Cabin     Lname  \\\n",
       "0     0.000000     1.0  1.0  0.571429  0.125    0.0  0.00  0.875  0.115340   \n",
       "1     0.001124     0.0  0.0  0.000000  0.125    0.0  0.75  0.250  0.209919   \n",
       "2     0.002247     1.0  0.0  1.000000  0.000    0.0  0.00  0.875  0.379469   \n",
       "3     0.003371     0.0  0.0  1.000000  0.125    0.0  0.75  0.250  0.307958   \n",
       "4     0.004494     1.0  1.0  1.000000  0.000    0.0  0.25  0.875  0.017301   \n",
       "\n",
       "   NamePrefix  \n",
       "0    0.575758  \n",
       "1    0.606061  \n",
       "2    0.484848  \n",
       "3    0.606061  \n",
       "4    0.575758  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 15]\n",
      " [26 42]]\n",
      "0.77094972067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.791742119383  -  0.790491839928\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "classifiers = {}\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.793190252627  -  0.797317236754\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.79598759222  -  0.79598759222\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SVM\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.734225911022  -  0.734225911022\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.79590878605  -  0.79590878605\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LR\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.781843281914  -  0.781843281914\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.821400625978  -  0.829794321484\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RF\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.800313547954  -  0.800313547954\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 1)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"ADA\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.792176391683  -  0.793604963112\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 30,learning_rate = 1)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.72692432372  -  0.72692432372\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "#clf.set_params(max_iter = 1000,alpha = 0.01)\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"PT\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "NN\n",
      " :  0.795988710038    0.794598144422\n",
      "DNN\n",
      " :  0.790254303599    0.807316118936\n",
      "SVM\n",
      " :  0.79598759222    0.79598759222\n",
      "NB\n",
      " :  0.734225911022    0.734225911022\n",
      "LR\n",
      " :  0.79590878605    0.79590878605\n",
      "KNN\n",
      " :  0.781843281914    0.781843281914\n",
      "RF\n",
      " :  0.836857254639    0.822749273418\n",
      "ADA\n",
      " :  0.800313547954    0.800313547954\n",
      "GB\n",
      " :  0.792196512408    0.799218645205\n",
      "PT\n",
      " :  0.72692432372    0.72692432372\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers after feature scaling\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we see the performance of various classifiers has improved dramatically after feature \n",
    "#But we see that Random Forest still is our best performing classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
