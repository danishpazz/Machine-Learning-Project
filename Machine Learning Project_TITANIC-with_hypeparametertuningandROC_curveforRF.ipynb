{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sys,os\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>854</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Lines, Miss. Mary Conover</td>\n",
       "      <td>female</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17592</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>D28</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>643</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Skoog, Miss. Margit Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>347088</td>\n",
       "      <td>27.9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>789</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Dean, Master. Bertram Vere</td>\n",
       "      <td>male</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 2315</td>\n",
       "      <td>20.5750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Daniel, Mr. Robert Williams</td>\n",
       "      <td>male</td>\n",
       "      <td>27.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113804</td>\n",
       "      <td>30.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldschmidt, Mr. George B</td>\n",
       "      <td>male</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17754</td>\n",
       "      <td>34.6542</td>\n",
       "      <td>A5</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>572</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hamalainen, Master. Viljo</td>\n",
       "      <td>male</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250649</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mamee, Mr. Hanna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2677</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>591</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rintamaki, Mr. Matti</td>\n",
       "      <td>male</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O 2. 3101273</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Lefebre, Master. Henry Forbes</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4133</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Simonius-Blumer, Col. Oberst Alfons</td>\n",
       "      <td>male</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13213</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A26</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>638</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Collyer, Mr. Harvey</td>\n",
       "      <td>male</td>\n",
       "      <td>31.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>C.A. 31921</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>390</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Lehmann, Miss. Bertha</td>\n",
       "      <td>female</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC 1748</td>\n",
       "      <td>12.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>645</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Baclini, Miss. Eugenie</td>\n",
       "      <td>female</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2666</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "853          854         1       1   \n",
       "642          643         0       3   \n",
       "887          888         1       1   \n",
       "788          789         1       3   \n",
       "607          608         1       1   \n",
       "96            97         0       1   \n",
       "571          572         1       1   \n",
       "755          756         1       2   \n",
       "36            37         1       3   \n",
       "590          591         0       3   \n",
       "176          177         0       3   \n",
       "647          648         1       1   \n",
       "637          638         0       2   \n",
       "389          390         1       2   \n",
       "644          645         1       3   \n",
       "\n",
       "                                              Name     Sex    Age  SibSp  \\\n",
       "853                      Lines, Miss. Mary Conover  female  16.00      0   \n",
       "642                  Skoog, Miss. Margit Elizabeth  female   2.00      3   \n",
       "887                   Graham, Miss. Margaret Edith  female  19.00      0   \n",
       "788                     Dean, Master. Bertram Vere    male   1.00      1   \n",
       "607                    Daniel, Mr. Robert Williams    male  27.00      0   \n",
       "96                       Goldschmidt, Mr. George B    male  71.00      0   \n",
       "571  Appleton, Mrs. Edward Dale (Charlotte Lamson)  female  53.00      2   \n",
       "755                      Hamalainen, Master. Viljo    male   0.67      1   \n",
       "36                                Mamee, Mr. Hanna    male    NaN      0   \n",
       "590                           Rintamaki, Mr. Matti    male  35.00      0   \n",
       "176                  Lefebre, Master. Henry Forbes    male    NaN      3   \n",
       "647            Simonius-Blumer, Col. Oberst Alfons    male  56.00      0   \n",
       "637                            Collyer, Mr. Harvey    male  31.00      1   \n",
       "389                          Lehmann, Miss. Bertha  female  17.00      0   \n",
       "644                         Baclini, Miss. Eugenie  female   0.75      2   \n",
       "\n",
       "     Parch             Ticket     Fare Cabin Embarked  \n",
       "853      1           PC 17592  39.4000   D28        S  \n",
       "642      2             347088  27.9000   NaN        S  \n",
       "887      0             112053  30.0000   B42        S  \n",
       "788      2          C.A. 2315  20.5750   NaN        S  \n",
       "607      0             113804  30.5000   NaN        S  \n",
       "96       0           PC 17754  34.6542    A5        C  \n",
       "571      0              11769  51.4792  C101        S  \n",
       "755      1             250649  14.5000   NaN        S  \n",
       "36       0               2677   7.2292   NaN        C  \n",
       "590      0  STON/O 2. 3101273   7.1250   NaN        S  \n",
       "176      1               4133  25.4667   NaN        S  \n",
       "647      0              13213  35.5000   A26        C  \n",
       "637      1         C.A. 31921  26.2500   NaN        S  \n",
       "389      0            SC 1748  12.0000   NaN        C  \n",
       "644      1               2666  19.2583   NaN        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in training data\n",
    "training_data = pd.read_csv(\"/Users/vishaladdala/Desktop/TITANIC/dataset/train.csv\")\n",
    "training_data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data statistics using .describe()\n",
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Transformations\n",
    "#method to convert ages to bins called 'Unknown'for [-1,0], 'Baby' for [0-5],\n",
    "#'Child' for [6-12], 'Teenager' for [13-19], 'Student' for [20-25], 'Young Adult' for [26-35], 'Adult' for [36-60],\n",
    "#'Senior' for [61-100]\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 19, 25, 35, 60, 100)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method which simplifies the cabin feature by filling N/A values with 'N'\n",
    "#also it takes only the first letter the cabin using splicing\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to convert fares into bins using the numbers from .descrobe() statistics earlier\n",
    "#the N/A values are filled with -0.5\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Extraction \n",
    "#the below method is used to extract two features from the Name column\n",
    "#method to format the Name column to extract LName and NamePrefix\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method to drop the features which we inconsider inconsequential\n",
    "#we have selected ticket,Name,Embarked columns to be dropped due lack of variance or too many N/A values\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this method calls all the above transformation methods one by one and applies it on our dataframe\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we proceed to proceed to apply the transformations on the training data\n",
    "transformed_train = transform_features(training_data)\n",
    "transformed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as we can see above our training data now has :\n",
    "#1. LName, NamePrefix instead of 'Name' which has been dropped\n",
    "#2. 'Ticket', 'Name', 'Embarked' have been dropped \n",
    "#3. 'Fare', 'Age' have been converted into convenient bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1099</td>\n",
       "      <td>2</td>\n",
       "      <td>Collett, Mr. Sidney C Stuart</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28034</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1235</td>\n",
       "      <td>1</td>\n",
       "      <td>Cardeza, Mrs. James Warburton Martinez (Charlo...</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17755</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1297</td>\n",
       "      <td>2</td>\n",
       "      <td>Nourney, Mr. Alfred (Baron von Drachstedt\")\"</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2166</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>D38</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1104</td>\n",
       "      <td>2</td>\n",
       "      <td>Deacon, Mr. Percy William</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O.C. 14879</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>905</td>\n",
       "      <td>2</td>\n",
       "      <td>Howard, Mr. Benjamin</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24065</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "207         1099       2                       Collett, Mr. Sidney C Stuart   \n",
       "343         1235       1  Cardeza, Mrs. James Warburton Martinez (Charlo...   \n",
       "405         1297       2       Nourney, Mr. Alfred (Baron von Drachstedt\")\"   \n",
       "212         1104       2                          Deacon, Mr. Percy William   \n",
       "13           905       2                               Howard, Mr. Benjamin   \n",
       "\n",
       "        Sex   Age  SibSp  Parch         Ticket      Fare        Cabin Embarked  \n",
       "207    male  24.0      0      0          28034   10.5000          NaN        S  \n",
       "343  female  58.0      0      1       PC 17755  512.3292  B51 B53 B55        C  \n",
       "405    male  20.0      0      0  SC/PARIS 2166   13.8625          D38        C  \n",
       "212    male  17.0      0      0   S.O.C. 14879   73.5000          NaN        S  \n",
       "13     male  63.0      1      0          24065   26.0000          NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we proceed to apply the above feature transformations on the test data\n",
    "test_data = pd.read_csv(\"/Users/vishaladdala/Desktop/TITANIC/dataset/test.csv\")\n",
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Kelly,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Wilkes,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Myles,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Wirz,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Hirvonen,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex          Age  SibSp  Parch        Fare Cabin  \\\n",
       "0          892       3    male  Young Adult      0      0  1_quartile     N   \n",
       "1          893       3  female        Adult      1      0  1_quartile     N   \n",
       "2          894       2    male       Senior      0      0  2_quartile     N   \n",
       "3          895       3    male  Young Adult      0      0  2_quartile     N   \n",
       "4          896       3  female      Student      1      1  2_quartile     N   \n",
       "\n",
       "       Lname NamePrefix  \n",
       "0     Kelly,        Mr.  \n",
       "1    Wilkes,       Mrs.  \n",
       "2     Myles,        Mr.  \n",
       "3      Wirz,        Mr.  \n",
       "4  Hirvonen,       Mrs.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_test = transform_features(test_data)\n",
    "transformed_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now as a next step, we need to remember that machine learning algorithms need all the input to be numerical values\n",
    "#But as we can observe from above 'Sex', 'Age' , 'Fare', 'Cabin', 'Lname', 'NamePrefix' are in nominal(string) format\n",
    "#Hence we need to convert these into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7    100   \n",
       "1            2         1       1    0    0      1      0     3      2    182   \n",
       "2            3         1       3    0    7      0      0     0      7    329   \n",
       "3            4         1       1    0    7      1      0     3      2    267   \n",
       "4            5         0       3    1    7      0      0     1      7     15   \n",
       "\n",
       "   NamePrefix  \n",
       "0          19  \n",
       "1          20  \n",
       "2          16  \n",
       "3          20  \n",
       "4          19  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we proceed to use LabelEncoder from sklearn preprocessing to achieve \n",
    "#Every column in numerical form\n",
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "    \n",
    "data_train, data_test = encode_features(transformed_train, transformed_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>401</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>843</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>552</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>851</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>342</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  NamePrefix\n",
       "0          892       3    1    7      0      0     0      7    401          19\n",
       "1          893       3    0    0      1      0     0      7    843          20\n",
       "2          894       2    1    3      0      0     1      7    552          19\n",
       "3          895       3    1    7      0      0     1      7    851          19\n",
       "4          896       3    0    4      1      1     1      7    342          20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we proceed to test the various classifiers in Scikit-Learn to \n",
    "#see which classifiers works best on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "#Below we are splitting up our training data into 80% training , 20% testing data \n",
    "# X contains all the columns except 'Survived' because that is the feature we predict\n",
    "# Y consists only of the column 'Survived'\n",
    "X = data_train.drop(['Survived'], axis=1)\n",
    "Y = data_train.Survived\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 15]\n",
      " [22 46]]\n",
      "0.793296089385\n"
     ]
    }
   ],
   "source": [
    "#Our first classifier will be Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.542117706237  -  0.577236194947\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "classifiers = {}\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.505573999553  -  0.578625083836\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.618025933378  -  0.618025933378\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SVM\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.533551307847  -  0.533551307847\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.681056338028  -  0.681056338028\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LR\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.563109769729  -  0.563109769729\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.821282696177  -  0.825528727923\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RF\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.800313547954  -  0.800313547954\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 1)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"ADA\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.800587413369  -  0.793545159848\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 30,learning_rate = 1)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GB\"]=clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.532415045831  -  0.532415045831\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "#clf.set_params(max_iter = 1000,alpha = 0.01)\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"PT\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "NN\n",
      " :  0.581383858708    0.552237871674\n",
      "DNN\n",
      " :  0.516906438632    0.588741895819\n",
      "SVM\n",
      " :  0.618025933378    0.618025933378\n",
      "NB\n",
      " :  0.533551307847    0.533551307847\n",
      "LR\n",
      " :  0.681056338028    0.681056338028\n",
      "KNN\n",
      " :  0.563109769729    0.563109769729\n",
      "RF\n",
      " :  0.819854124748    0.815687458082\n",
      "ADA\n",
      " :  0.800313547954    0.800313547954\n",
      "GB\n",
      " :  0.793565280572    0.794954169461\n",
      "PT\n",
      " :  0.532415045831    0.532415045831\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hence we see that Random forest classifier gave the best performance with an accuracy ~83% and an F-score ~83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next we proceed to apply \"Feature Scaling\" to see if the performance of our various classifiers improves\n",
    "#Feature scaling aims to bring the values of our numerical features between 0 and 1\n",
    "#This is mainly done because large numerical values may skew our data and make the classifier weight it more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XX = data_train.drop(['Survived'], axis=1)\n",
    "YY = data_train.Survived\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "XX[XX.columns] = scaler.fit_transform(XX[XX.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.209919</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.379469</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp  Parch  Fare  Cabin     Lname  \\\n",
       "0     0.000000     1.0  1.0  0.571429  0.125    0.0  0.00  0.875  0.115340   \n",
       "1     0.001124     0.0  0.0  0.000000  0.125    0.0  0.75  0.250  0.209919   \n",
       "2     0.002247     1.0  0.0  1.000000  0.000    0.0  0.00  0.875  0.379469   \n",
       "3     0.003371     0.0  0.0  1.000000  0.125    0.0  0.75  0.250  0.307958   \n",
       "4     0.004494     1.0  1.0  1.000000  0.000    0.0  0.25  0.875  0.017301   \n",
       "\n",
       "   NamePrefix  \n",
       "0    0.575758  \n",
       "1    0.606061  \n",
       "2    0.484848  \n",
       "3    0.606061  \n",
       "4    0.575758  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 10)\n",
      "(179, 10)\n",
      "(712,)\n",
      "(179,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96 15]\n",
      " [26 42]]\n",
      "0.77094972067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred =  dtree.predict(X_test)\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Nueral Network:\n",
      "0.790273865415  -  0.790353230494\n"
     ]
    }
   ],
   "source": [
    "# Artifical Neural Network\n",
    "classifiers = {}\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100), max_iter = 1000,alpha = 0.01, momentum = 0.7)\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Artificial Nueral Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network:\n",
      "0.783290856249  -  0.798705007825\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network\n",
    "clf = MLPClassifier()\n",
    "clf.set_params(hidden_layer_sizes =(100,100,100,100), max_iter = 100,alpha = 0.3, momentum = 0.7,activation = \"relu\")\n",
    "nn_clf = clf.fit(X_train,Y_train)\n",
    "nn_predict = nn_clf.predict(X_test)\n",
    "nn_acc = accuracy_score(Y_test,nn_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Deep Neural Network:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"DNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.79598759222  -  0.79598759222\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\")\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"SVM\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "0.734225911022  -  0.734225911022\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "clf.set_params(alpha = 0.1)\n",
    "nb_clf = clf.fit(X_train,Y_train)\n",
    "nb_predict = nb_clf.predict(X_test)\n",
    "nb_acc = accuracy_score(Y_test,nb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"NB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "0.79590878605  -  0.79590878605\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.set_params(C = 10, max_iter = 10)\n",
    "lr_clf = clf.fit(X_train,Y_train)\n",
    "lr_predict = lr_clf.predict(X_test)\n",
    "lr_acc = accuracy_score(Y_test,lr_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Logistic Regression:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"LR\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN :\n",
      "0.781843281914  -  0.781843281914\n"
     ]
    }
   ],
   "source": [
    "#k-NN Classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.set_params(n_neighbors= 5,leaf_size = 30)\n",
    "knn_clf = clf.fit(X_train,Y_train)\n",
    "knn_predict = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(Y_test,knn_predict)\n",
    "param =  knn_clf.get_params()\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"k-NN :\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"KNN\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.822691146881  -  0.828464676951\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RF\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:\n",
      "0.800313547954  -  0.800313547954\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "clf = AdaBoostClassifier()\n",
    "clf.set_params(n_estimators = 10, learning_rate = 1)\n",
    "ada_clf = clf.fit(X_train,Y_train)\n",
    "ada_predict = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(Y_test,ada_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"AdaBoost:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"ADA\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "0.797790073776  -  0.799218645205\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.set_params(n_estimators = 30,learning_rate = 1)\n",
    "gb_clf = clf.fit(X_train,Y_train)\n",
    "gb_predict = gb_clf.predict(X_test)\n",
    "gb_acc = accuracy_score(Y_test,gb_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"GB\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron:\n",
      "0.72692432372  -  0.72692432372\n"
     ]
    }
   ],
   "source": [
    "#Perceptron\n",
    "clf = linear_model.Perceptron()\n",
    "#clf.set_params(max_iter = 1000,alpha = 0.01)\n",
    "pt_clf = clf.fit(X_train,Y_train)\n",
    "pt_predict = pt_clf.predict(X_test)\n",
    "pt_acc = accuracy_score(Y_test,pt_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Perceptron:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"PT\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy                F-score\n",
      "NN\n",
      " :  0.784778672032    0.798825732171\n",
      "DNN\n",
      " :  0.798786049631    0.80160295104\n",
      "SVM\n",
      " :  0.79598759222    0.79598759222\n",
      "NB\n",
      " :  0.734225911022    0.734225911022\n",
      "LR\n",
      " :  0.79590878605    0.79590878605\n",
      "KNN\n",
      " :  0.781843281914    0.781843281914\n",
      "RF\n",
      " :  0.81711602951    0.824218645205\n",
      "ADA\n",
      " :  0.800313547954    0.800313547954\n",
      "GB\n",
      " :  0.790767940979    0.793604963112\n",
      "PT\n",
      " :  0.72692432372    0.72692432372\n"
     ]
    }
   ],
   "source": [
    "#Here we print the performance of the various classifiers after feature scaling\n",
    "print (\"accuracy\",\"              \",\"F-score\")\n",
    "for clf in classifiers.values():\n",
    "    accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "    f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "    for i in classifiers:\n",
    "        if classifiers[i]== clf:\n",
    "            print (i),\n",
    "            break\n",
    "    print ( \" : \",accuracy.mean(), \"  \",f_score.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we see the performance of various classifiers has improved dramatically after feature \n",
    "#But we see that Random Forest still is our best performing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Trying the concept of hyperparameter tuning using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.322 (+/-0.005) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.322 (+/-0.005) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.322 (+/-0.005) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.322 (+/-0.005) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.713 (+/-0.103) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.322 (+/-0.005) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.698 (+/-0.084) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.713 (+/-0.103) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.703 (+/-0.092) for {'C': 1, 'kernel': 'linear'}\n",
      "0.681 (+/-0.088) for {'C': 10, 'kernel': 'linear'}\n",
      "0.681 (+/-0.088) for {'C': 100, 'kernel': 'linear'}\n",
      "0.681 (+/-0.088) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.85       406\n",
      "          1       0.78      0.71      0.74       263\n",
      "\n",
      "avg / total       0.81      0.81      0.81       669\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.697 (+/-0.082) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.678 (+/-0.060) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.697 (+/-0.082) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.685 (+/-0.072) for {'C': 1, 'kernel': 'linear'}\n",
      "0.668 (+/-0.066) for {'C': 10, 'kernel': 'linear'}\n",
      "0.668 (+/-0.066) for {'C': 100, 'kernel': 'linear'}\n",
      "0.668 (+/-0.066) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.87      0.85       406\n",
      "          1       0.78      0.71      0.74       263\n",
      "\n",
      "avg / total       0.81      0.81      0.81       669\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine\n",
    "\n",
    "#clf = svm.SVC()\n",
    "#clf.set_params(C = 100, kernel = \"rbf\")\n",
    "#svm_clf = clf.fit(X_train,Y_train)\n",
    "#svm_predict = svm_clf.predict(X_test)\n",
    "#svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "#accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "#f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "#print(\"Support Vector Machines:\")\n",
    "#print (accuracy.mean(), \" - \",f_score.mean())\n",
    "#classifiers[\"SVM\"]=clf\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.75, random_state = 5)\n",
    "\n",
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                       scoring='%s_macro' % score)\n",
    "    clf.fit(X_train,Y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines:\n",
      "0.728722002635  -  0.728722002635\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.set_params(C = 100, kernel = \"rbf\", gamma= 0.001)\n",
    "svm_clf = clf.fit(X_train,Y_train)\n",
    "svm_predict = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(Y_test,svm_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Support Vector Machines:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 2.23 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.725 (std: 0.036)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 3, 'max_features': 6, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.721 (std: 0.063)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 6, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.721 (std: 0.048)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 6, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
      "\n",
      "GridSearchCV took 33.71 seconds for 324 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.734 (std: 0.035)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.734 (std: 0.019)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.025)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.041)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.043)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 10, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.043)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10, 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.730 (std: 0.068)\n",
      "Parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "X, y = X_train,Y_train\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3,10, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.706192358366  -  0.723800112931\n"
     ]
    }
   ],
   "source": [
    "#Model with rank: 1\n",
    "#Mean validation score: 0.734 (std: 0.028)\n",
    "#Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 5, 'min_samples_leaf': 4, 'min_samples_split': 6}\n",
    "\n",
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10, max_features = 3, criterion = 'entropy')\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n",
    "classifiers[\"RF\"]=clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.70146809712  -  0.720280444193\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.115340</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.209919</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.379469</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.307958</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex       Age  SibSp  Parch  Fare  Cabin     Lname  \\\n",
       "0     0.000000     1.0  1.0  0.571429  0.125    0.0  0.00  0.875  0.115340   \n",
       "1     0.001124     0.0  0.0  0.000000  0.125    0.0  0.75  0.250  0.209919   \n",
       "2     0.002247     1.0  0.0  1.000000  0.000    0.0  0.00  0.875  0.379469   \n",
       "3     0.003371     0.0  0.0  1.000000  0.125    0.0  0.75  0.250  0.307958   \n",
       "4     0.004494     1.0  1.0  1.000000  0.000    0.0  0.25  0.875  0.017301   \n",
       "\n",
       "   NamePrefix  \n",
       "0    0.575758  \n",
       "1    0.606061  \n",
       "2    0.484848  \n",
       "3    0.606061  \n",
       "4    0.575758  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.825528169014  -  0.825548848647\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10)\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "0.817077464789  -  0.832610663984\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.set_params(n_estimators = 100, max_depth = 10, max_features = 3, criterion = 'entropy')\n",
    "rf_clf = clf.fit(X_train,Y_train)\n",
    "rf_predict = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(Y_test,rf_predict)\n",
    "accuracy = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'accuracy')\n",
    "f_score = cross_val_score(clf, X_train , Y_train, cv=10,scoring = 'f1_micro')\n",
    "print(\"Random Forest Classifier:\")\n",
    "print (accuracy.mean(), \" - \",f_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishaladdala/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.87\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAETCAYAAADd6corAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVKDwUGS1GBwkCQ1GBwkSQ3vKDL/knNzGR8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ad01d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    " \n",
    "# shuffle and split training and test sets\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size = 0.20, random_state = 5)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(XX, YY, test_size=.25)\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "#clf.set_params(n_estimators = 100, max_depth = 10, max_features = 3, criterion = 'gini')\n",
    "#rf_clf = clf.fit(X_train,Y_train)\n",
    "#rf_predict = rf_clf.predict(X_test)\n",
    "\n",
    "forest.fit(X_train, Y_train)\n",
    " \n",
    "# Determine the false positive and true positive rates\n",
    "fpr, tpr, _ = roc_curve(Y_test, forest.predict_proba(X_test)[:,1])\n",
    " \n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print ('ROC AUC: %0.2f' % roc_auc)\n",
    " \n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
